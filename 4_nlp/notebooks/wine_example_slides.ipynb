{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "import pyLDAvis\n",
    "from pyLDAvis import sklearn as sklearn_lda\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <span style=\"color:red\"> Topic Classification of Wine Reviews: A Worked Example </span>\n",
    "\n",
    "## Data Skills for Empirical Research\n",
    "\n",
    "### Winter 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <span style=\"color:red\"> Overview </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <span style=\"color:red\"> Goals </span>\n",
    "<center><img src=\"../figures/wine_bottle.jpg\" width=\"20%\" style=\"border:5px solid #000000\"/></center>\n",
    "\n",
    "* We want to determine the substitutability of wines for online retailers using text reviews - if two wines are substitutes, then we expect that reviews about them will be similar\n",
    "* To determine similarity, we want to know what each review is talking about from a broad topic level - ideally, we additionally want some quantitative metric of topic distance\n",
    "* Since the corpus of reviews is quite large, we want an unsupervised machine learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <span style=\"color:red\"> Solution: Latent Dirichlet Allocation (LDA) </span>\n",
    "\n",
    "* Latent Dirichlet Allocation (LDA) is a topic model which models documents as mixtures of underlying topics - which topic a document belongs to is determined by the words it contains\n",
    "* By using a bag-of-words model, LDA represents each latent topic as a multinomial distribution over the words in a text - these latent topics can be captured using an unsupervised Bayesian learning algorithm\n",
    "* Advantages\n",
    "\n",
    "    * Ease of use with the scikit-learn package\n",
    "    * Relatively low cost to implement as an unsupervised algorithm - no PoS tagging necessary, for example\n",
    "    \n",
    "* Disadvantages\n",
    "\n",
    "    * Validation of topics must be performed manually\n",
    "    * Metrics of model fit do not necessarily indicate overall model quality (but other metrics can be used, e.g. Jensen-Shannon Divergence, topic coherence)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <span style=\"color:red\"> Procedure </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <span style=\"color:red\"> Pipeline Overview </span>\n",
    "1. Load in review corpus and fit a count vectorizer to the text\n",
    "2. Create a LDA model with a specified number of topics and fit the model to the vectorized text\n",
    "\n",
    "    * Optional: perform a grid-search cross validation over a number of topics to find the best fit\n",
    "    \n",
    "3. Get estimated term frequencies of the most frequent terms in each topic\n",
    "4. Get the probability of a review belonging to each of the $n$ specified categories\n",
    "5. Write out an HTML visualization of the topics in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "First, read in the review corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of wines in the sample: 20\n",
      "Number of total reviews: 200\n"
     ]
    }
   ],
   "source": [
    "reviews=pd.read_csv('../data/wine_reviews_sample.csv')\n",
    "print(\"Number of wines in the sample: %d\" % len(reviews['wine_id'].unique()))\n",
    "print(\"Number of total reviews: %d\" % reviews.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "After reading in the data, load the review text into a Count Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "count_vectorizer=CountVectorizer(stop_words='english')\n",
    "count_data=count_vectorizer.fit_transform(reviews['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Next, specify some number of topics for the LDA model; in the original wine project, five topics were specified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_topics=5\n",
    "lda_model=LDA(n_components=num_topics)\n",
    "lda_model.fit(count_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now that the model has been fitted to the corpus with the proper number of topics, we want to get the top 10 most frequent words and their estimated term frequency for each topic. This is done like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           1     1_freq        2     2_freq        3     3_freq        4  \\\n",
      "Rank                                                                       \n",
      "1       nice  15.687043     good  11.221647    great  13.938013   medium   \n",
      "2     finish  14.210360     wine   8.209898      red  10.912524   finish   \n",
      "3       nose  13.199232     just   6.211955    apple  10.166098     body   \n",
      "4      fruit  13.045087     nose   6.207802  brioche   8.200480   cherry   \n",
      "5       good  12.568816   finish   5.204493     wine   7.860729    apple   \n",
      "6     really  12.071051   medium   4.206883   finish   7.634476      red   \n",
      "7        red  10.503312  tannins   4.205597    lemon   7.200686      med   \n",
      "8        dry  10.145933    great   4.204606   citrus   6.960853    lemon   \n",
      "9     cherry   9.473008      red   4.200181    value   6.942235  acidity   \n",
      "10    palate   8.180290    fruit   4.198380   cherry   6.584335     nose   \n",
      "\n",
      "         4_freq           5     5_freq  \n",
      "Rank                                    \n",
      "1     13.851720      cherry  27.546345  \n",
      "2     13.242621        nose  23.886687  \n",
      "3     12.088032      palate  21.269221  \n",
      "4     11.200947        wine  20.530321  \n",
      "5     11.021576       fruit  19.918393  \n",
      "6     10.278793         red  19.105191  \n",
      "7      9.200390      earthy  18.200079  \n",
      "8      9.199307  strawberry  17.199199  \n",
      "9      8.335220   raspberry  17.182036  \n",
      "10     8.269813       great  15.654480  \n"
     ]
    }
   ],
   "source": [
    "n_top_words=10\n",
    "words=count_vectorizer.get_feature_names()\n",
    "output_dict={}\n",
    "for topic_idx,topic in enumerate(lda_model.components_):\n",
    "    top_features_ind=topic.argsort()[:-n_top_words-1:-1]\n",
    "    top_features=[words[i] for i in top_features_ind]\n",
    "    weights=topic[top_features_ind]\n",
    "    output_dict[(topic_idx+1)]=top_features\n",
    "    output_dict[('%s_freq' % str((topic_idx+1)))]=weights\n",
    "output_df=pd.DataFrame.from_dict(output_dict)\n",
    "output_df.index=output_df.index.rename('Rank')\n",
    "output_df.index=output_df.index+1\n",
    "print(output_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Our next task is to get the probability of each review belonging to one of these categories, as well as identifying which category a review most likely belongs to. This is accomplished thusly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   wine_id                                               text   topic_1  \\\n",
      "0  1248751  Bright, fresh, and lighter bodied with a long ...  0.029179   \n",
      "1  1248751                 cherry raspberry earthy strawberry  0.040417   \n",
      "2  1248751  A real big surprising Pinot Noir with a bunch ...  0.020126   \n",
      "3  1248751  Excellent pinot noir, very drinkable, doesn't ...  0.022507   \n",
      "4  1248751  Nice cherry taste, a little earthy with just e...  0.925697   \n",
      "5  1248751  Totally good Pinot for Coastal California - in...  0.009381   \n",
      "6  1248751  Great wine for the price. Delicate on the pall...  0.020281   \n",
      "7  1248751  Red fruit: strawberry, raspberry, cherry. Cont...  0.015746   \n",
      "8  1248751  Bright and fresh Sonoma Pinot. Red cherry, str...  0.018380   \n",
      "9  1248751  Nice Pinot Noir from California. Grapes source...  0.018537   \n",
      "\n",
      "    topic_2   topic_3   topic_4   topic_5  predicted_topic  \n",
      "0  0.029268  0.883258  0.029192  0.029102                3  \n",
      "1  0.040211  0.040081  0.040306  0.838984                5  \n",
      "2  0.392327  0.020168  0.020224  0.547155                5  \n",
      "3  0.022308  0.910143  0.022433  0.022609                3  \n",
      "4  0.018618  0.018431  0.018443  0.018810                1  \n",
      "5  0.009274  0.962807  0.009219  0.009319                3  \n",
      "6  0.020331  0.020252  0.020173  0.918964                5  \n",
      "7  0.015503  0.015462  0.015565  0.937723                5  \n",
      "8  0.018315  0.018427  0.018390  0.926488                5  \n",
      "9  0.018214  0.018372  0.018391  0.926486                5  \n"
     ]
    }
   ],
   "source": [
    "reviews_fitted=lda_model.transform(count_vectorizer.transform(reviews['text']))\n",
    "predicted_topic=np.argmax(reviews_fitted,axis=1)+1\n",
    "fitted_output=pd.DataFrame(reviews_fitted,columns=(np.arange(num_topics)+1))\n",
    "fitted_output.columns=['topic_'+str(col) for col in fitted_output.columns]\n",
    "fitted_output.index=reviews.index\n",
    "fitted_output=pd.concat([reviews,fitted_output],axis=1)\n",
    "fitted_output['predicted_topic']=predicted_topic\n",
    "print(fitted_output.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Finally, to get wine-level predicted topics we do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    wine_id  mode_review_topic\n",
      "0   1248751                  5\n",
      "1   7122486                  3\n",
      "2     86684                  4\n",
      "3   1288838                  5\n",
      "4   1141123                  5\n",
      "5   1248038                  3\n",
      "6      9119                  4\n",
      "7   1194720                  5\n",
      "8   1578948                  5\n",
      "9      3069                  2\n",
      "10  1153696                  5\n",
      "11  1399928                  1\n",
      "12  1380949                  1\n",
      "13  1733954                  1\n",
      "14    83195                  4\n",
      "15  1842942                  5\n",
      "16    19265                  1\n",
      "17  1944048                  1\n",
      "18    15615                  4\n",
      "19  1209439                  5\n"
     ]
    }
   ],
   "source": [
    "wine_list=[]\n",
    "mode_topic=[]\n",
    "for wine in fitted_output['wine_id'].unique():\n",
    "    wine_list.append(wine)\n",
    "    mode_topic.append(fitted_output[fitted_output['wine_id']==wine]['predicted_topic'].mode().values[0])\n",
    "wine_topic_df=pd.DataFrame({'wine_id':wine_list,'mode_review_topic':mode_topic})\n",
    "print(wine_topic_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One last useful tool is the PyLDAVis package, which provides an interactive visualization of the LDA model we have fitted to the reviews. This is a relatively simple procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "LDAVis_prepared=sklearn_lda.prepare(lda_model,count_data,count_vectorizer)\n",
    "pyLDAvis.save_html(LDAVis_prepared,'../html_output/wine_pyldavis.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <span style=\"color:red\"> References </span>\n",
    "* Wang, Wenxin, Yi Feng, and Wenqiang Dai. “Topic Analysis of Online Reviews for Two Competitive Products Using Latent Dirichlet Allocation.” Electronic Commerce Research and Applications 29 (May 1, 2018): 142–56. https://doi.org/10.1016/j.elerap.2018.04.003.\n",
    "* “Topic Extraction with Non-Negative Matrix Factorization and Latent Dirichlet Allocation — Scikit-Learn 0.24.1 Documentation.” Accessed January 29, 2021. https://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html.\n",
    "* “2.5. Decomposing Signals in Components (Matrix Factorization Problems) — Scikit-Learn 0.24.1 Documentation.” Accessed January 29, 2021. https://scikit-learn.org/stable/modules/decomposition.html#latentdirichletallocation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <span style=\"color:red\"> Packages Used - For Future Reference </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "import pyLDAvis\n",
    "from pyLDAvis import sklearn as sklearn_lda"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
